#Raft

##总览

Raft使用SRM(state replication machine)实现容错服务。基本架构是客户端，多个副本服务器。
每个副本服务器都使用相同顺序执行相同的操作，其最终结果是：执行一系列命令后产生相同的结果。若其中一个服务器发生故障，其他副本服务器会接管服务。GFS和VMware FT中都有类似功能。

###状态机
状态机是一个可以被复制的应用或服务。其具有内部状态，由顺序的输入命令组成，执行后生成输出。“顺序”意味着非并行，而且命令必须是确定性的，状态机不能与外界其他状态机进行交互。


**关键问题：如何避免“多leader”**

* 假设client可以与副本A交互，但不能与副本B交互，client是否可以只与A进行交互？当然不行！
* 若B发生故障，我们必须进行继续提供服务，否则不能称之为“容错”
* 若B运行正常但与集群网络不连通，由于B可能正常运行并服务于其他client，这可能会造成“多leader”
* 网络分区：通常，我们不能区分出“机器故障”和“网络分区”


**方法：单master**

* 有一个简单的方法是使用一个单独的“master”，由于只有一个master，不需要担心产生master不一致的情况。client通过访问master与整个系统进行交换。但是如果master发生故障怎么办？这是一个“故障单点”(指发送故障后整个系统不可用)，所以方案并不是很好。

* 我们想要的是一个复制状态机方案：整个系统没有“故障单点”，即使有机器发生故障，系统也可以提供服务；并且能够处理网络分区和多leader问题。

**应对分区：多数投票**

* 集群一般有2f+1台服务器，例如，3或5。
* 多数是指必须获得(f+1)投票才能成为“主服务器”。
* 可以处理整个集群中有f台服务器发生异常，因此无故障单点。
* 也没有多leader，这是因为最多只有一台及其能够获得多数投票
* 注意：多数的分母是所有服务器的数量2f+1，而非运行的数量；最关键的是多数机器之间互相连通，服务器只能投票一次。


**复制策略**

目前两个主要的复制策略在1990左右年发明：

* Paxos和View-Stamped Replication
* 过去10年中，已经有很多系统在使用这些技术
* Raft非常好的描述了SRM的思想。
* MapReduce、GFS、VMware FT都受益于SRM。MapReduce的master没有使用复制；GFS master有复制功能但不会自动切换到备份；WMware FT使用共享磁盘原子性检查并设置，也未使用复制。


##Raft总览

* 有三个或以上副本
* Raft选择一个服务器作为leader
* client向leader的k/v层发送RPC请求：Put/Get/Append
* leader将每个client命令发送到所有副本，每个follower都追加命令到自己的日志中；这样做的目的是多个副本中保存相同的日志；在此过程中，会将并发的client请求Put(a,1) Put(a,2)转换为一致的顺序
* 当多数服务器将命令追加到自己的日志中时，entry成为“已提交”的。
* 当leader通知服务器“已提交”后，才会执行entry。k/v层应用Put到DB，或者Get获取结果
* 然后leader向client回复执行结果


服务保持状态机的状态，例如：key/value数据库中即是其保存的数据。
若一个follower丢失了leader的command时，怎样有效地处理使之恢复到最新数据？答案是重新发送丢失的command。

**log**

* log是command的序列，等效于状态机的状态。开始state+log=最终state。log同时包含一个编号，用于指定操作的序号。log还是一个临时的保存区域，直到我们确认command被commit。
* log不能作为额外的副本，这是因为某些副本可能落后于log；多个log中包含不同的entries。
* 如果server已经执行了一个指定entry编号的command，其他server也会同样执行相同编号的command。


##Raft接口

**rf.Start**

* rf.Start(command)(index,term,isleader)
* 启动一个新的log entry
* 立即返回；随后成功或失败
* 如果server在commit之前失去了leader的地位，可能不会成功
* index指定了需要查看的log entry

**ApplyMsg**

* 当service（k/v服务）应该执行新的command时，Raft生成一条消息。通知leader中client的RPC handler，可以向client回复信息。


##Raft算法

对于Raft的算法设计，有两个要点：

* 选举新leader
* 确保故障前后的log相同

有三个状态：

* leader 用于接收client请求
* candidate 候选者
* follower 跟随者

**Raft对leader进行顺序编号**

新leader对应着新的term，term是逻辑时钟
一个term最多只有一个leader，也可能没有leader；编号用于帮助服务器找到最新的leader，而非过期的leader

**Raft何时开始选举？**

follower服务器在一段时间内未收到当前leader的心跳；增加当前的term，变为candidate，开始选举。

如何保证一个term最多只有一个leader？
leader必须获得大多数服务器的投票；每个服务器针对每个term只能投票一次，只对第一次请求投票；一个term中最多只有一个服务器能够得到大多数投票；

**服务器如何知道选举成功？**

选举成功后，leader会发送AppendEntries心跳，其他服务器收到后可以知道选举成功。

**选举失败**

选举失败的情况：3个或以上candidate拆分了投票，没有服务器能够获得大多数选票；超过一半服务器不能连通。

选举失败后如何处理？超时后，增加当前term，变为candidate状态；更高的的term有更高的优先级，旧term的candidate会退出candidate状态。

**Raft如何避免拆分选举失败？**

每个server在开始候选者之前延迟一段随机时间；原因是：将会选择随机时间最小的服务器作为候选者；在下次超时时间过期前有足够的时间选举；其他服务器收到leader的AppendEntries心跳后不会变为candidate

**怎样选择随机延迟时间的范围？**

如果太短：第二个candidate会在第一个candidate选举完成前启动；如果太长：leader发生故障后系统会等待过长时间。
解决方法：假设花费10ms完成一个成功的选举，有5台服务器，我们需要为每个等待20ms，因此随机延迟从0到100ms

**Raft选举通用模式：**

软机制尝试确保过程，通常能够安全的在一个新term启动一个新选举；软机制尝试避免不必要的选举：leader的心跳提醒server不要开始选举；超时时间不会让选举启动的太快；随机延迟给了leader足够的选举时间。

**老的leader不知道有新的leader选举产生**

可能旧leader没有收到选举消息；新的leader的term比旧leader的term高，所以旧leader的AppendEntries不能成功；老leader不会commit或执行新的log entries；因此，不会发生多个leader的情况。但是少数服务器可能接收老服务器的AppendEntries，因此log可能偏离正确的log。


**注意**

* leader不应该等待AppendEntries RPCs的回复。这是因为：在服务器故障时不能阻塞；每个在一个goroutine中发送；这意味着RPC可能顺序颠倒。



**一致性**

通过prevLogTerm机制，新leader强制follower的log与其相等。

新leader是否可以回滚前一个term已经执行的entry？例如：新leader的log是否可以不包含在一个已经执行的entry？这会是一个灾难--破坏了状态机的安全性；Raft会选举一个包含所有已执行entry的leader。

**安全性**
下面的log中我们可以选择的leader？
S1： 5 6 7
S2： 5 8
S3： 5 8
首先，我们先讨论这种情况是否会发生？会如何发生？
S1是term6的leader，发生故障后重启；继续作为term7的leader；发生故障后停止。
S2是term8的leader，只有S2和S3运行，然后发生故障；
下一个leader是谁呢?
S1有最长的log，但是entry8可能已经执行，因此新leader只能是S2或S3。规则不只是简单地“最长的log”

5.4.1节的最后解释了“至少最新”的投票原则：比较最后一个entry，term最高的可以可以成为leader，若term相等，选择log最长的，因此只有S2或S3可以成为leader，并强制S1删除6,7。（6和7保存成功但是多数服务器未保存，因此不会执行，也不会像client回复成功，删除是安全的）。
上述的原则保证了新leader的log包含所有可能执行的entries，因此新leader不会回滚任务已执行的entry。


论文图7中，最上面的服务器发生故障，a/d/f哪个会成为leader？
图7中选择的leader不同，不同的entry会被commit或删除
C的6和d的7可能会被删除或提交，111445566将会一直保持提交状态


**怎么快速回滚？**

图2设计的每个RPC备份一个entry的效率太低，速度太慢。我们需要快读的回滚
S1： 4 4 4 4
S2： 4 4 5 5 6 6
S3： 4 4 5 5
S3被选择为term=7的leader（S2并不在多数投票中，因为最后一个entry的term比5大）
论文在5.3的末尾大概描述了方法：如果follower拒绝，会回复：发生冲突的entry的term；如果leader知道冲突的term；移动nextIndex[i]到冲突term的最后一个entry；否则移动nextIndex[i]到follower的第一个index

为什么图2中服务器需要遵守故障log[N].term==currentTerm？图8描述了一个例子：
S1： 1 2       1 2 4
S2： 1 2       1 2
S3： 1     --> 1 2
S4： 1         1
S5： 1         1 3

S1是term2的leader，发送2到副本
S5是term3的leader
S1是term4的leader，发送多个2（b/c S3拒绝了4）
如果S5现在变为leader，S5会回滚2，使用3代替之。因此“在多数服务器上不等于已提交”

entry在下面两者情况下回被提交：
* term中多数服务器保存了entry
* 如果随后的log被提交

###持久化和性能

如果服务器发送故障并重启，需要保存的信息：

* 图2列出了需要持久化的状态：currentTerm，voteFor，log[]
* Raft服务器重启后，只有数据完整后才能重新加入集群
* 这些信息修改后必须保存在持久化保存
* 如果重启的服务器不在提交entry的多数服务器中，重启后，其他服务器不一定能恢复log，因此需要持久化log[]
* 保存currentTerm/votedFor的目的是方式重启后在同一个term为不同服务器重新投票，这可能导致一个term存在两个leader

状态机的状态不需要保存，因为Raft持久化了整个log，重启后，lastApplied重置为0，Raft将会发送给服务器，回放将会重新生成状态机的状态。（快照技术稍微修改了一些）

**瓶颈**
通常持久化是性能瓶颈：

* 硬盘写花费10ms，SSD写花费0.1ms
* RPC花费在1ms一下
* 我们期望每秒100到10000次操作
* 很多服务并不需要很高的性能，批量并行client操作，使用快速非易失存储器可以提高性能


**吞吐量**

* 不通过向一个Raft集群添加服务器，更多的服务器意味着更多的故障；更多的服务器需要更多的leader操作，会降低吞吐；
* 为了更多的吞吐，可以采取共享或拆分数据的方法。许多Raft集群，一般是3到5台机器；不同的集群可以并行工作，因为他们不需要交互；使用Raft对master进行容错时复制数据的效率更高。

**放弃性能是为了更容易理解?**

* 很多复制系统有相似的性能：一次RPC交互和一次磁盘写入。
* 某些Raft设计可能会影响性能：Raft的follower拒绝乱序的AppendEntries RPC，而不是一直保存到填上空洞之后；速度慢的leader会影响Raft。


**实践中性能的重点**

* 考虑使用的原因（put/get 还是偶尔的重新配置）
* 批量写入PRC和磁盘
* 只读请求给快读路径
* 高效的RPC库
* Raft可能与大多数类似技术不兼容
* 关于性能的论文：Zookeeper/ZAB; Paxos Made Live; Harp


###client
client用于与整个系统进行交互：

* client发送Put/Append/Get RPC
* 怎么样找到leader
* leader崩溃后，client如何处理

**client RPC循环**

* 发送RPC到服务器
* RPC调用将会返回：错误或回复响应
* 如果回复，服务器是leader，返回
* 如果无回复或服务器回复无leader，尝试另一个服务器
* client应该焕春最后一个已知的leader


**问题：这将产生重复的client请求**

* client发送请求给leader S1，S1写入多数服务器的log
* S1在回复client前失败
* client看到RPC错误，等待新leader，重新发送给新leader
* 新leader再次将请求写入log

**我们需要“最多一次”机制解决这个问题：**

* 每个服务器应该记住已执行的client请求
* 如果一个请求已经出现在log中，则不执行，回复执行执行的结果
* Raft通过为请求添加编号处理重复请求。

所有副本都需要维护一个检测重复的表，不只是leader，因为所有server都可能变为leader，client可能重复发送到某台服务器。

C1 发送get(x),服务器执行结果1，leader在回复client前崩溃
C2 发送put(x,2)
C2 重新发送get(x)给最新的leader，从表中可知返回1
应用可以从为复制的服务器得到1吗？

C1 发送get(x)，很快执行，但通过网络回复的很慢，所以在C2的put(x,2)后client收到回复。


**副作用**

* leader是否可以在本地执行只读命令？是否可以不向followers发送AppendEntries并等待commit？这个操作非常有诱惑力，因为R/O操作可以控制状态机而不改变其状态
* 为什么这可能是个坏主意？怎么让这个想法能够故障？

###log压缩和快照

问题：如果不断添加到log中，log会变得很大，比状态机的状态要大得多。这将会使用很多内存，同步follower时花费更多的时间，重启后也需要更多的时间读取数据。

丢弃log的旧数据时需要哪些约束？不能忘记未commit的操作；如果发生故障或重启后需要回复client，需要使得其他服务器更新到最新数据

**解决方法**

* 在通过一个特定的log entry拷贝整个状态机状态，例如：k/v表，clietn复制状态
* 服务将快照写入持久化存储器中，通知Raft生成快照结束，Raft删去此entry之前的log
* 服务器可以自任何时候创建快照并删除之前的log

在实验三中，你需要实现这个功能，你的Raft实现不需要存储删除的log entries，例如：Go 垃圾收集器必须能够释放内存。所以你需要稍微灵活的数据结构。

**快照和log的关系**

* 快照只可以包含已经commit的log entries
* 服务器只能删除已commit的前缀log，所有不知道是否commit的都会保存在log中
* 因此，服务器磁盘状态由所有log组成。即：快照中的log、接下来持久化在log entry，两者加起来就是整个log。

崩溃后重启会发生什么？服务器从磁盘中读取快照，Raft从磁盘读取持久化的log，leader向服务器发送不在磁盘中但已commit的entries。

**InstallSnapshot**

* 若term是旧的（不是当前term的leader）则拒绝
* 若我们已经有一个index/term或者已经执行了最后一个包含的index；若是一个旧的，延迟后RPC
* 清空log，替换为prev entry
* 将lastApplied设置为lastIncludedIndex
* 发送快照在applyCh
* 服务器替换lastApplied，k/v表，client复制table

问题：InstallSnapshot RPC是否可能导致状态机回到从前的状态？图13中的step8导致状态机重置以至于影响少数执行的操作？如果是，解释如何发生的。如果不是，解释为什么不会发生。


###更新配置

配置=服务器集合，有时用户可能需要移动到一个新的服务器集合或者增加/删除服务器数量。


假设当前配置中，每个服务器有一个服务器列表，更新配置时通知每台服务器新的服务器列表
例如：将S3替换为S4

S1: 1,2,3   1,2,4
S2: 1,2,3   1,2,3
S3: 1,2,3   1,2,3
S4: _ ,_ ,_ 1,2,4
现在可以选出两个leader：S2和S3选举S2;S1和S4选举S1


**Raft更新配置**
思路：joint consensus包含新的和旧的配置
旧配置的leader切换为joint consensus
在joint consensus，leader发送通过AppendEntriesRPC修改配置，提交后，再发送新配置
S1：1,2,3   1,2,3+1,2,4
S2：1,2,3
S3：1,2,3
S4: ====   1,2,3+1,2,4

不会发生同时存在两个leader，一个使用old的配置，一个使用新配置。如果发生故障，
若崩溃后，新leader看不到新旧配置，旧集群会继续保持。若新leader可以看到新旧配置，则可以完成配置切换。










