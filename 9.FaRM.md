# FaRM
---

今天学习的论文是：No compromises: distributed transactions with consistency, availability, and performance
通常，分布式事务的速度都比较慢，本节论文描述的系统具有了惊人的高性能，下面我们来看看他们是如何做到的。


以论文中的图7为例，集群共有90台机器，每台256GB内存，其性能为：

* 每秒9千万次事务（包括复制，持久化，commit），每台机器每秒处理1百万次事务
* 复制和commit交互过程中涉及的数据很少
* 性能非常惊人
* 其他的系统（如memcached）每台机器可以达到每秒1百万次操作（并非事务）
* 某些情况下，我们需要这样高性能的系统，以9千万/秒的性能为例，我们可以在一秒内处理1万个tweets或2百万封email。


##高性能秘籍

* 数据全部存放在主存中（不从磁盘读）
* 使用非易失RAM，内存（不向磁盘写）
* 高速网络
* 高效使用CPU，且基本上只处理网络相关操作
* FaRM的写操作不写入磁盘，而是RAM，这避免了一个很大的瓶颈。
* 写入RAM只需200ns，而写入硬盘需要10ms，SSD需要100us
* RAM在失电的情况下会丢失内容，不能持久化保存。我们可以写入f台计算机的RAM,来进行容错。如果故障是独立的话可以这样做，但是电源故障通常不是独立的，可能会涉及到所有的机器。
* 因此，如果主电源发生故障时立刻启动备用电源，软件系统可以知道何时发生电源故障，并停止所有进行中的事务，将 FaRM的RAM中的内容写入SSD。然后机器可以安全的进行关闭。
* 重启时，FaRM从SSD中读取保存的内存数据。

有些故障可能导致不能写入SSD，例如内核bug，cpu/内存/硬件发生错误，幸运的是这些故障是独立的，因此f+1个副本中最多可以有f个副本发生故障。


###网络瓶颈

通常的系统进行网络通信时，会进行如下操作：

* 服务器S1上的应用向S2上的应用发送数据
* write()进行系统调用
* 将数据拷贝到内核缓存中
* 根据内核的协议进行组装，如TCP
* 内核将数据发送到网卡
* 网卡将数据组装为数据包，发送到S2的网卡
* S2的网卡通过DMA方式将数据传输到内存
* 发出中断
* 执行内核TCP代码（接收程序）
* read()进行系统调用
* 拷贝到用户内存。

上述过程是一个复杂且很慢的流程，构造一个每秒调用超过10万次的RPC是很困难的。（实验中labrpc不使用网络的情况下，每个RPC需要花费20us，也就是每秒5万次。）
对于短RPC来说，网络很少能够成为主要瓶颈，10GB/S的电缆即可满足。此时，CPU对每个网络包进行处理的时间成为了最主要的限制。

FaRM的网络操作

* 网卡使用“单边RDMA”：内存读写，不传输包
* 发送者发出“向这个地址写入这些数据”或“从这个地址读取数据”的指令，网卡在远端执行操作并返回一个硬件的确认信号。
* 整个过程中远端无中断、内核处理，拷贝、read()操作
* 这样，每台服务器可以达到千万/秒以上的吞吐（图2）

FaRM在三个方面使用RDMA：执行中的事务单边读取数据；单边写入备份的log；RPC由单边写入主服务器log和消息队列组成

##应用

应用到网卡的连接是流线型的，应用直接与网卡进行交互，不需要系统调用，也不需要通过内核。发送者向网卡发送RDMA命令，接收服务器轮询检查内存中需要处理的消息或log entries。
轮询需要程序能够处理交错的情况，高负载时下的效率更高，而中断在低负载时效率较高。
对于采用FaRm的机器来说，上述方法的效率较高。但若多个应用需要共享网卡时，传统的内核策略更有效。

###API设计

理想中的事务API
```
begin()
o = get(oid)
o.f += 1
put(oid, o)
ok = commit()
```

FaRM的API与传统事务的API不同，系统需要通过并发执行多个事务来提高性能。而对于上面的代码，多个线程并发执行时，线程切换需要几微秒，速度比较慢。
RDMA只花费5微秒，因此FaRM中切换事务的速度要比5微秒更快。
因此，FaRM的API(2014的NSDI论文)为:
```
f1()
    tx = create()
    txRead(tx, oid, f2)
f2(tx, o)
    txWrite(tx, oid, o, o1)
    o1.f += 1
    txCommit(tx, f4)
 f4(tx, ok)
...
```
上述API采用“事件驱动”的方式，在函数内部注册回调处理函数，然后轮询外部的输入，收到后调用回调函数处理这些写入的数据。
在事务的运行过程中只包含一个函数调用，这比线程切换的速度要快。
传统的竞争相关的概念，如：线程、阻塞调用、内核、中断，通常不能带来非常高的性能

因此，每个核心交错运行多个活动，并且都在用户层:
```
loop:
    轮询获取输入的msg/log，放入RDMA队列
    调用相应的事务回调方法
    无回调时，当为新log entry处理
```

**oid的内容**

```
<region #,offset>
```
* region # 是一个索引，映射到主服务器
* offset是主服务器的内存地址
* 发送者可以依此简单的计算出RDMA的地址，因此目标服务器的CPU不需要进行读操作

**服务器内存布局**

* region是一个对象数组
* 对象布局：头部有版本号#和锁,每个缓存行（cache line）都包含版本号#。（高速缓存可分配的最小存储单位，一个L1 DATA CACHE相当于一块小的内存，我们假设它为16K大，它会与一般物理内存交互。它和内存交互一般一次传输16个字节(32个字节),也就是:CACHE 字节0-15一次写到/读取物理内存 ，字节16-31一次写到/读取物理内存.32-47 ... ... 这些一次被传输的字节被称为cache line）
* 其他服务器通过RDMA写操作，轮询执行读操作
* 这些操作都在非易失RAM中(故障时写入SSD)

每个region保存在一个主服务器，f个备份服务器，共f+1个副本。只有主服务器可以执行读操作，少于等于f台服务器发生故障时，可以完成事务提交，并保证系统的可用性。


**txRead**

单边RDMA直接快速地从主服务器拉取数据，如果主服务器正在更新数据的过程中，由于每个cache line都包含版本号#，reader此时会看到两个版本号#s,reader会重试RDMA操作，直至所有版本号都是#s。
事务完成后，reader不会缓存数据。如果在其他事务commit之前进行读取，此时的数据是过期的。

**txWrite**

必须先txRead再txWrite，txWrite不需要进行通讯，只需在本地分配的对象副本上进行修改，调用txCommit时通知修改的内容write set（写入的内容）。
在commit期间，客户端作为自己的TC(transaction coordinator)，

###流程

图4描述了无故障时事务执行及提交协议的过程，其中的并发控制和两阶段提交非常类似：

**LOCK**

* TC向要写入对象所在的所有主服务器发送锁
* TC使用RDMA将锁追加到每台主服务器的log中
* 锁记录包含我们read出的oid，version#，写入的value(还有其他一些内容)
* 由于不经过cpu，主服务器需要轮询log，检查LOCK，校验是否可以加锁，返回“yes”或“no”
* TC等待响应信息

主服务器在接收LOCK时，如果对象已经被锁住或者version与事务读取的version不等，返回“no”，TC会退出事务；否则设置锁标志并返回“yes”。这些操作由主服务器的CPU完成。
注意：如果对象已经被锁，不要阻塞等待而是直接退出。

**COMMIT-PRIMARY**

* TC向每个写入对象的主服务器发送COMMIT-PRIMARY
* 使用RDMA追加到主服务器的log
* TC只需要等待硬件的确认已经收到数据，不需要等待主服务处理日志
* TC收到确认后，通过调用txCommit回调尽快向应用返回“yes”

主服务器对log处理时，首先拷贝内存对象中新的值，再增加对象的版本号version#，最后清除对象的锁标志

例子
```
T1 and T2 both want to increment x
both say
    tmp = read(x)
    tmp += 1
    write(x)
```
x的结果可能是0, 1, 或 2 ，这依赖于有多少事务成功commit。

T1和T2不同执行时：
```
T1：Rx0 Lx  Cx
T1：Rx0 Lx  Cx

T1:    Rx0 Lx Cx
T2: Rx0          Lx  Cx

T1: Rx0  Lx   Cx
T2:        Rx?   Lx  Cx
```

Thor通过时间戳和VQ实现串行化，而FaRM使用锁和版本号完成串行化。

独占锁强制有冲突的事务按照顺序执行，所以执行顺序不同，意义也不相同。校验时要求后处理的事务可以看到前面写入的数据，发生冲突时其中一个事务会退出。

如果后来的事务与之前的事务有重叠，则后来的事务退出；如果后面的事务没有重叠则可以提交。

假定T1先获得锁，若T1在T2的Rx之前提交，T2可以看到T1的写入；若T1在T2的Rx之后提交，T2的LOCK阶段会看到锁或者更高的版本号，T2退出；若T1和T2的Rx同时提交，会按照顺序保证缓存的一致性。

事务成功获得锁的时候也就确定了多个事务的执行顺序，这个时间称为“串行化点”。因为其为冲突的事务定义了等价的串行顺序。

**validate**

* 单边RDMA读时获取对象当前的版本号#和锁标志，如果已经设置了锁或版本号读之后发生变化，退出事务。
* validate阶段不需要设置锁，速度比LOCK快

```
x and y 初始都是0
T1:
  if x == 0:
    y = 1
T2:
  if y == 0:
    x = 1
```
这是一个诊断一致性的经典例子。
T1,T2的结果： y=1,x=0
T2,T1的结果： x=1,y=0
我们不希望得到由于读写冲突而产生x=1,y=1的结果。我们希望VALIDATE时确定顺序

假定同时发生：
T1:  Rx  Ly  Vx  Cy
T2:  Ry  Lx  Vy  Cx

两个事务的LOCK阶段都会成功（x和y设置更高的版本号）；由于设置了锁，VALIDATE阶段会失败（此阶段看到了更高的版本号）；所以两个事务都会退出，这是正确的。

假设T1的Vx发生在T2的Lx之前，然后T1可以提交，T2由于Vy时看到了T1的锁，T2退出事务。这样可以保证串行化。


###容错

FaRM使用副本保存数据，即使某些服务发生故障，系统依然可以处理请求。
FaRM复制LOCK/COMMIT的日志，以便服务器恢复后可以完成事务。

ZooKeeper集群由少量副本服务器组成，只用于保存配置#,服务器的配置集合和CM。
CM（Configuration Manager）不使用副本。用于将数据分片到主从集合上。CM检测所有服务器的状态，对每个分片，保存在1个主服务器和f台副本服务器上。

TC在写入主服务器之前会一直等待副本服务器的响应，如果发生故障，CM会通知TC并启动重配置（reconfiguration）

假设出现网路分区（这是最有趣的故障情况），最多有一个分区可以与ZooKeeper通信，这是因为ZooKeeper使用了一个类Raft的多数算法（超过半数才能继续服务）。
一台机器会成为新的CM，其他的服务器（主服务器和备份服务器）将会与CM互相通信。
CM针对每个数据分片只需要一台备份服务器；CM收集所有服务器的log找出活动事务的集合；CM使用log信息决定每个事务是否已经提交。

尽管有服务器发生故障，但任何事务都可能已经提交了。

TC收到LOCK和Validate阶段的yes后，TC将COMMIT-BACKUP追加到每个副本服务器的日志中，收到所有确认后，TC追加COMMIT-PRIMARY到每台主服务器的日志，收到确认后，向应用返回“commit”。

注意：由TC复制到副本服务器，而不是由主服务器完成。 COMMIT-BACKUP包括写入的值等，这些数据足以更新备份服务器的状态。

TC只有在收到所有COMMIT-BACKUP的确认信息后才发送COMMIT-PRIMARY，主服务器收到后会尽快的执行并显示其他事务的更新。
因此，每个对象写入的新值必须记录在f+1台服务器日志中，这样f台服务器发生故障也不会丢失数据。
如果只有一台备份服务器没有COMMIT-BACKUP，只向f个服务器写入新值，若所有的f与TC通信失败，会导致永久性丢失写入的值。因此，必须向所有备份中写入COMMIT-BACKUP才能继续。

在写入主服务器之前，只有f个备份服务器通过COMMIT-BACKUP写入了新数据，为了防止f台服务发生故障丢失数据，TC需要等待COMMIT-PRIMARY的确认响应。

###FaRM的特点

* 冲突较少的情况下，性能最高（类似OCC）
* 数据必须全部放在RAM中
* 数据模型比较抵触，可能需要诸如SQL之类的库
* 事务API依靠回调